{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass Classifier(Rock Paper Scissors).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wszXZqtw_UPk",
        "outputId": "49004fa3-1ec1-4969-b162-02e2da46ce20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-27 12:13:54--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 74.125.31.128, 142.250.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200682221 (191M) [application/zip]\n",
            "Saving to: ‘/tmp/rps.zip’\n",
            "\n",
            "/tmp/rps.zip        100%[===================>] 191.38M   238MB/s    in 0.8s    \n",
            "\n",
            "2022-06-27 12:13:55 (238 MB/s) - ‘/tmp/rps.zip’ saved [200682221/200682221]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "!wget --no-check-certificate \\\n",
        "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \\-O /tmp/rps.zip\n",
        "local_zip = '/tmp/rps.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/')\n",
        "zip_ref.close()\n",
        "TRAINING_DIR = \"/tmp/rps/\"\n",
        "training_datagen = ImageDataGenerator(\n",
        " rescale = 1./255,\n",
        " rotation_range=40,\n",
        " width_shift_range=0.2,\n",
        " height_shift_range=0.2,\n",
        " shear_range=0.2,\n",
        " zoom_range=0.2,\n",
        " horizontal_flip=True,\n",
        " fill_mode = 'nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data = training_datagen.flow_from_directory('/tmp/rps/',target_size = (150,150),class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XweWuR-Z_fz5",
        "outputId": "fc776196-3af1-43f4-c94a-10037ea37d07"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2520 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tensorflow.keras.Sequential([\n",
        "    tensorflow.keras.layers.Conv2D(64,(3,3),input_shape=(150,150,3),activation = 'relu'),\n",
        "    tensorflow.keras.layers.MaxPool2D((2,2)),\n",
        "    tensorflow.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
        "    tensorflow.keras.layers.MaxPool2D((2,2)),\n",
        "    tensorflow.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "    tensorflow.keras.layers.MaxPool2D((2,2)),\n",
        "    tensorflow.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "    tensorflow.keras.layers.MaxPool2D((2,2)),\n",
        "    tensorflow.keras.layers.Flatten(),\n",
        "    tensorflow.keras.layers.Dense(512,activation ='relu'),\n",
        "    tensorflow.keras.layers.Dense(3,activation= 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "TSAvJk0_AgBX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'rmsprop',loss= 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "azxSWcBGBzcH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(tr_data,epochs = 10,verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VArtDTzPChIF",
        "outputId": "d16c92a4-adda-4c1d-83aa-f3e501464ec1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 178s 2s/step - loss: 1.1745 - accuracy: 0.3631\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 174s 2s/step - loss: 0.8735 - accuracy: 0.5825\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 173s 2s/step - loss: 0.5367 - accuracy: 0.7683\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 174s 2s/step - loss: 0.3559 - accuracy: 0.8675\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 174s 2s/step - loss: 0.2475 - accuracy: 0.9155\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 174s 2s/step - loss: 0.1940 - accuracy: 0.9325\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 176s 2s/step - loss: 0.1842 - accuracy: 0.9365\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 175s 2s/step - loss: 0.1315 - accuracy: 0.9552\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 174s 2s/step - loss: 0.1341 - accuracy: 0.9560\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 175s 2s/step - loss: 0.0872 - accuracy: 0.9694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f965c018750>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "XqH7VKIGMgis"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('scissors.jpg',target_size = (150,150))"
      ],
      "metadata": {
        "id": "gIV1p3vhM9pV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.img_to_array(img)"
      ],
      "metadata": {
        "id": "dSTFkVP3NHO3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NQqATy3NNXZ",
        "outputId": "4dbdbc2e-5733-4c60-f431-30727a11c5e6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.expand_dims(img,axis = 0)"
      ],
      "metadata": {
        "id": "HWtnQTf_NOfP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkHyY0clNW6n",
        "outputId": "99187ae4-9fb0-464b-8c51-574bac342f65"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.vstack([x])"
      ],
      "metadata": {
        "id": "lPopU9XCNXyq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification = model.predict(x)"
      ],
      "metadata": {
        "id": "B8FFiuXONa55"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification)# labels are chronological : Paper;Rock;Scissors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya87KsYRNemA",
        "outputId": "496c1af3-4010-4f76-e6ec-d64bfe527f60"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Rock_Paper_scissors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlCMfSrqNwNx",
        "outputId": "0803d706-0a49-405c-ddfe-f9b793f670fe"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Rock_Paper_scissors/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/model_RPS.zip /content/Rock_Paper_scissors/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYj4_ODpPyNY",
        "outputId": "9a22707b-5ff5-47eb-8b0e-27ccff65fbbe"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Rock_Paper_scissors/ (stored 0%)\n",
            "  adding: content/Rock_Paper_scissors/variables/ (stored 0%)\n",
            "  adding: content/Rock_Paper_scissors/variables/variables.index (deflated 66%)\n",
            "  adding: content/Rock_Paper_scissors/variables/variables.data-00000-of-00001 (deflated 14%)\n",
            "  adding: content/Rock_Paper_scissors/saved_model.pb (deflated 89%)\n",
            "  adding: content/Rock_Paper_scissors/keras_metadata.pb (deflated 93%)\n",
            "  adding: content/Rock_Paper_scissors/assets/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2wxoJNsnP8s3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}